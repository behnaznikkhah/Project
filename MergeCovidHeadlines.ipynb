{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MergeCovidHeadlines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPovRIb3PCXPwnM9flbdkpa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/behnaznikkhah/Project/blob/master/MergeCovidHeadlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MhUy_6IVQmD"
      },
      "source": [
        "# MergeCovidHeadlines.py\n",
        "\n",
        "# Sai Madhuri Yerramsetti\n",
        "# November 5, 2020\n",
        "# Student Number: 0677671\n",
        "\n",
        "# import required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "# disable warning in case chained assignment of pandas dataframes\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Function to combine the headline strings, filter covid related news and merge then\n",
        "def merge_and_save_data(file_dir):\n",
        "    \n",
        "    # initialize variables\n",
        "    filepath_list = []\n",
        "    news = []\n",
        "    hyphen_elements = []\n",
        "    hyphen_count = 0\n",
        "\n",
        "    # Create a list of covid-19 related words\n",
        "    filter_words = ['covid', 'pandemic', 'coronavirus', 'quarantine', 'cov2', 'corona virus', 'social distancing']\n",
        "\n",
        "    # Get the list of csv files \n",
        "    file_path = os.path.abspath(file_dir)\n",
        "    filepath_list = [os.path.join(file_path, f) for f in os.listdir(file_path) if f.endswith('.CSV')]\n",
        "\n",
        "    # combines all the headlines data in a file list, take last two columns to get date and news url and name them\n",
        "    unclean_data = pd.concat([pd.read_csv(f, sep=\"\\t\", header=None, engine='python') for f in filepath_list])\n",
        "    corona_news = unclean_data.iloc[:, -2:]\n",
        "    corona_news.columns = ['Date', 'NewsLink']\n",
        "\n",
        "    # This loop goes through each url in NewsLink column and get the headline data\n",
        "    for url in corona_news['NewsLink']:\n",
        "        # split the url at '/'\n",
        "        news_item = url.split('/')\n",
        "\n",
        "        # for each element of the splitted url get the strings with more than 2 hyphens\n",
        "        for item in news_item:\n",
        "            if '-' in item:\n",
        "\n",
        "                # loop to count the number of hyphens in the url strings\n",
        "                for char in item:\n",
        "                    if char == \"-\" :\n",
        "                        hyphen_count += 1\n",
        "\n",
        "                # Filter out the string with less then 2 hyphens as new websites contained one or two hyphens in them similar to headlines\n",
        "                if (hyphen_count > 2):\n",
        "                    hyphen_elements.append(item)\n",
        "            hyphen_count = 0\n",
        "\n",
        "        # Filter out unnecessary session ids containing hyphens present at the end of urls and get only headline data after replacing hyphen with space\n",
        "        if(len(hyphen_elements) > 0):\n",
        "            news.append(hyphen_elements[0].replace('-',' '))\n",
        "\n",
        "        # If the string hyphens are none, then add news as empty string\n",
        "        if(len(hyphen_elements) == 0):\n",
        "            news.append('')        \n",
        "        hyphen_elements = []        \n",
        "\n",
        "    # Create a new column 'News' with headline data    \n",
        "    corona_news['News'] = news\n",
        "    del corona_news['NewsLink']\n",
        "\n",
        "    # Check the news with empty string news and drop those rows\n",
        "    print(\"Headlines with empty string: \\n\", corona_news[corona_news.News == ''])\n",
        "    corona_news = corona_news.drop(corona_news[corona_news.News == ''].index)\n",
        "    print(\"Dimensions of corona news dataframe is:\", corona_news.shape)\n",
        "\n",
        "    # Filter only covid-19 related headlines\n",
        "    corona_news = corona_news[corona_news['News'].str.contains('|'.join(filter_words), case = False)]\n",
        "\n",
        "    # Check the final covid-19 headlines data and check for any null values\n",
        "    print(\"Dimensions of the filtered data\", corona_news.shape)\n",
        "    print(corona_news.head(10))\n",
        "    print(\"Number of missing values: \", corona_news.isnull().values.any())\n",
        "\n",
        "    # Save the csv file\n",
        "    corona_news.to_csv(r'D:\\Madhuri\\Big Data Project\\News data\\corona_news\\corona_news_oct.csv', index = False, header=True)\n",
        "\n",
        "# If the corona news data for each months is taken seperately, need to run below code to combine all the months data\n",
        "def merge_corona_news_data(corona_news_path):\n",
        "\n",
        "    file_path = os.path.abspath(corona_news_path)\n",
        "    filepath_list = [os.path.join(file_path, f) for f in os.listdir(file_path) if f.endswith('.csv')]\n",
        "    corona_news = pd.concat([pd.read_csv(f) for f in filepath_list])\n",
        "\n",
        "    corona_news.to_csv(r'D:\\Madhuri\\Big Data Project\\News data\\corona_news\\corona_news.csv', index = False, header=True)\n",
        "    print(\"Merging monthly data is finished\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  file_dir = 'D:/Madhuri/Big Data Project/News data/Oct'\n",
        "  corona_news_path = 'D:/Madhuri/Big Data Project/News data/corona_news'\n",
        "  merge_and_save_data(file_dir)\n",
        "  #merge_corona_news_data(corona_news_path) #This function is only needed headlines of each month are processed and saved seperately\n",
        "  print(\"................Merging is done..................\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}